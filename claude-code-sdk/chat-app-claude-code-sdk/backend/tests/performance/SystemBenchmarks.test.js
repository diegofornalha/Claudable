/**\n * Performance Benchmarks para Sistema Kingston Enhanced\n * Valida performance, throughput e escalabilidade\n */\n\nconst request = require('supertest');\nconst { performance } = require('perf_hooks');\nconst EventEmitter = require('events');\nconst cluster = require('cluster');\nconst os = require('os');\n\n// Mock app para testes\nconst express = require('express');\nconst app = express();\napp.use(express.json());\n\n// Configuração de benchmarks\nconst BENCHMARK_CONFIG = {\n  WARMUP_REQUESTS: 50,\n  BENCHMARK_REQUESTS: 1000,\n  CONCURRENT_USERS: [1, 5, 10, 25, 50],\n  MAX_RESPONSE_TIME: 2000, // 2s\n  MIN_THROUGHPUT: 100, // req/min\n  MIN_SUCCESS_RATE: 0.95,\n  MEMORY_LIMIT: 512 * 1024 * 1024, // 512MB\n  CPU_THRESHOLD: 80 // 80%\n};\n\n// Mock endpoints para benchmark\napp.get('/api/health', (req, res) => {\n  res.json({ status: 'healthy', timestamp: Date.now() });\n});\n\napp.get('/api/enhanced/status', (req, res) => {\n  // Simula processamento\n  setTimeout(() => {\n    res.json({\n      enabled: true,\n      metrics: {\n        totalTasks: Math.floor(Math.random() * 1000),\n        successRate: 0.95 + Math.random() * 0.05\n      }\n    });\n  }, Math.random() * 100);\n});\n\napp.post('/api/enhanced/execute', (req, res) => {\n  const startTime = performance.now();\n  \n  // Simula processamento intensivo\n  setTimeout(() => {\n    const duration = performance.now() - startTime;\n    res.json({\n      success: true,\n      result: {\n        success: true,\n        duration: Math.round(duration),\n        quality: {\n          passed: true,\n          overallScore: 8 + Math.random() * 2\n        }\n      }\n    });\n  }, 200 + Math.random() * 800);\n});\n\napp.post('/api/quality/evaluate', (req, res) => {\n  // Simula avaliação de qualidade\n  setTimeout(() => {\n    res.json({\n      success: true,\n      evaluation: {\n        overallScore: 7 + Math.random() * 3,\n        passed: Math.random() > 0.1\n      }\n    });\n  }, 100 + Math.random() * 200);\n});\n\napp.get('/api/workers/metrics', (req, res) => {\n  res.json({\n    pool: {\n      totalTasks: Math.floor(Math.random() * 500),\n      avgExecutionTime: 1000 + Math.random() * 2000\n    },\n    utilization: Math.random(),\n    timestamp: Date.now()\n  });\n});\n\napp.post('/api/structured/process', (req, res) => {\n  // Simula processamento estruturado\n  setTimeout(() => {\n    res.json({\n      success: true,\n      data: req.body.data,\n      metadata: {\n        processingTime: Date.now(),\n        validationPassed: true\n      }\n    });\n  }, 50 + Math.random() * 150);\n});\n\n// Classe para medição de performance\nclass PerformanceMonitor {\n  constructor() {\n    this.metrics = {\n      requests: 0,\n      responses: 0,\n      errors: 0,\n      totalTime: 0,\n      responseTimes: [],\n      throughput: 0,\n      concurrency: 0,\n      memoryUsage: [],\n      cpuUsage: []\n    };\n    \n    this.startTime = null;\n    this.endTime = null;\n  }\n\n  start() {\n    this.startTime = performance.now();\n    this.metrics = {\n      requests: 0,\n      responses: 0,\n      errors: 0,\n      totalTime: 0,\n      responseTimes: [],\n      throughput: 0,\n      concurrency: 0,\n      memoryUsage: [],\n      cpuUsage: []\n    };\n  }\n\n  recordRequest() {\n    this.metrics.requests++;\n  }\n\n  recordResponse(responseTime) {\n    this.metrics.responses++;\n    this.metrics.totalTime += responseTime;\n    this.metrics.responseTimes.push(responseTime);\n  }\n\n  recordError() {\n    this.metrics.errors++;\n  }\n\n  recordSystemMetrics() {\n    const memUsage = process.memoryUsage();\n    this.metrics.memoryUsage.push(memUsage.heapUsed);\n    \n    const cpuUsage = process.cpuUsage();\n    this.metrics.cpuUsage.push(cpuUsage.user + cpuUsage.system);\n  }\n\n  finish() {\n    this.endTime = performance.now();\n    const duration = (this.endTime - this.startTime) / 1000; // seconds\n    this.metrics.throughput = this.metrics.responses / (duration / 60); // req/min\n    \n    return this.getReport();\n  }\n\n  getReport() {\n    const responseTimes = this.metrics.responseTimes.sort((a, b) => a - b);\n    const successRate = this.metrics.responses / this.metrics.requests;\n    \n    return {\n      summary: {\n        totalRequests: this.metrics.requests,\n        totalResponses: this.metrics.responses,\n        totalErrors: this.metrics.errors,\n        successRate,\n        throughput: this.metrics.throughput,\n        duration: (this.endTime - this.startTime) / 1000\n      },\n      performance: {\n        avgResponseTime: this.metrics.totalTime / this.metrics.responses,\n        minResponseTime: Math.min(...responseTimes),\n        maxResponseTime: Math.max(...responseTimes),\n        p50ResponseTime: this.getPercentile(responseTimes, 0.5),\n        p95ResponseTime: this.getPercentile(responseTimes, 0.95),\n        p99ResponseTime: this.getPercentile(responseTimes, 0.99)\n      },\n      system: {\n        avgMemoryUsage: this.getAverage(this.metrics.memoryUsage),\n        maxMemoryUsage: Math.max(...this.metrics.memoryUsage),\n        avgCpuUsage: this.getAverage(this.metrics.cpuUsage)\n      }\n    };\n  }\n\n  getPercentile(arr, percentile) {\n    const index = Math.ceil(arr.length * percentile) - 1;\n    return arr[index] || 0;\n  }\n\n  getAverage(arr) {\n    return arr.length > 0 ? arr.reduce((a, b) => a + b, 0) / arr.length : 0;\n  }\n}\n\n// Função para load testing\nasync function loadTest(endpoint, options = {}) {\n  const {\n    method = 'GET',\n    data = null,\n    concurrency = 1,\n    requests = 100,\n    warmup = 10\n  } = options;\n\n  const monitor = new PerformanceMonitor();\n  \n  // Warmup\n  console.log(`🔥 Warming up with ${warmup} requests...`);\n  for (let i = 0; i < warmup; i++) {\n    try {\n      await request(app)[method.toLowerCase()](endpoint).send(data);\n    } catch (error) {\n      // Ignore warmup errors\n    }\n  }\n  \n  console.log(`📊 Starting load test: ${requests} requests, ${concurrency} concurrent users`);\n  monitor.start();\n  \n  // Create promises for concurrent execution\n  const promises = [];\n  const semaphore = new Array(concurrency).fill(0);\n  \n  for (let i = 0; i < requests; i++) {\n    const promise = new Promise(async (resolve) => {\n      // Wait for available slot\n      await waitForSlot(semaphore);\n      \n      const requestStart = performance.now();\n      monitor.recordRequest();\n      \n      try {\n        const response = await request(app)[method.toLowerCase()](endpoint).send(data);\n        const responseTime = performance.now() - requestStart;\n        \n        monitor.recordResponse(responseTime);\n        \n        if (response.status >= 400) {\n          monitor.recordError();\n        }\n      } catch (error) {\n        monitor.recordError();\n      }\n      \n      releaseSlot(semaphore);\n      resolve();\n    });\n    \n    promises.push(promise);\n    \n    // Record system metrics periodically\n    if (i % 50 === 0) {\n      monitor.recordSystemMetrics();\n    }\n  }\n  \n  await Promise.all(promises);\n  return monitor.finish();\n}\n\n// Utility functions for concurrency control\nfunction waitForSlot(semaphore) {\n  return new Promise((resolve) => {\n    const checkSlot = () => {\n      const availableIndex = semaphore.findIndex(slot => slot === 0);\n      if (availableIndex !== -1) {\n        semaphore[availableIndex] = 1;\n        resolve();\n      } else {\n        setTimeout(checkSlot, 1);\n      }\n    };\n    checkSlot();\n  });\n}\n\nfunction releaseSlot(semaphore) {\n  const busyIndex = semaphore.findIndex(slot => slot === 1);\n  if (busyIndex !== -1) {\n    semaphore[busyIndex] = 0;\n  }\n}\n\n// Test suites\ndescribe('Kingston Enhanced System - Performance Benchmarks', () => {\n  let server;\n  \n  beforeAll((done) => {\n    server = app.listen(0, () => {\n      console.log(`🧪 Test server running on port ${server.address().port}`);\n      done();\n    });\n  });\n\n  afterAll((done) => {\n    if (server) {\n      server.close(done);\n    } else {\n      done();\n    }\n  });\n\n  describe('Baseline Performance Tests', () => {\n    test('should handle health check requests efficiently', async () => {\n      const result = await loadTest('/api/health', {\n        requests: BENCHMARK_CONFIG.BENCHMARK_REQUESTS,\n        concurrency: 10,\n        warmup: BENCHMARK_CONFIG.WARMUP_REQUESTS\n      });\n\n      console.log('📊 Health Check Results:', result);\n\n      expect(result.summary.successRate).toBeGreaterThan(BENCHMARK_CONFIG.MIN_SUCCESS_RATE);\n      expect(result.performance.p95ResponseTime).toBeLessThan(500); // 500ms for health check\n      expect(result.summary.throughput).toBeGreaterThan(BENCHMARK_CONFIG.MIN_THROUGHPUT);\n    });\n\n    test('should maintain performance under concurrent load', async () => {\n      const results = [];\n      \n      for (const concurrency of BENCHMARK_CONFIG.CONCURRENT_USERS) {\n        console.log(`\\n🔄 Testing with ${concurrency} concurrent users...`);\n        \n        const result = await loadTest('/api/enhanced/status', {\n          requests: 200,\n          concurrency,\n          warmup: 20\n        });\n        \n        results.push({\n          concurrency,\n          ...result\n        });\n        \n        console.log(`Results for ${concurrency} users:`, {\n          successRate: result.summary.successRate,\n          avgResponseTime: Math.round(result.performance.avgResponseTime),\n          p95ResponseTime: Math.round(result.performance.p95ResponseTime),\n          throughput: Math.round(result.summary.throughput)\n        });\n        \n        // Basic performance assertions\n        expect(result.summary.successRate).toBeGreaterThan(0.9);\n        expect(result.performance.p95ResponseTime).toBeLessThan(BENCHMARK_CONFIG.MAX_RESPONSE_TIME);\n      }\n      \n      // Analyze scalability\n      const scalabilityReport = analyzeScalability(results);\n      console.log('\\n📈 Scalability Analysis:', scalabilityReport);\n      \n      expect(scalabilityReport.degradationRate).toBeLessThan(0.5); // Less than 50% degradation\n    });\n  });\n\n  describe('Enhanced Features Performance', () => {\n    test('should handle enhanced task execution efficiently', async () => {\n      const result = await loadTest('/api/enhanced/execute', {\n        method: 'POST',\n        data: {\n          task: {\n            content: 'Test task for performance benchmark',\n            type: 'text_generation'\n          }\n        },\n        requests: 100,\n        concurrency: 5,\n        warmup: 10\n      });\n\n      console.log('📊 Enhanced Task Execution Results:', result);\n\n      expect(result.summary.successRate).toBeGreaterThan(0.9);\n      expect(result.performance.p95ResponseTime).toBeLessThan(3000); // 3s for complex tasks\n      expect(result.system.maxMemoryUsage).toBeLessThan(BENCHMARK_CONFIG.MEMORY_LIMIT);\n    });\n\n    test('should handle quality evaluation workload', async () => {\n      const result = await loadTest('/api/quality/evaluate', {\n        method: 'POST',\n        data: {\n          result: 'Test content for quality evaluation',\n          task: { content: 'Test task', type: 'text_generation' }\n        },\n        requests: 200,\n        concurrency: 8,\n        warmup: 20\n      });\n\n      console.log('📊 Quality Evaluation Results:', result);\n\n      expect(result.summary.successRate).toBeGreaterThan(0.95);\n      expect(result.performance.avgResponseTime).toBeLessThan(1000); // 1s average\n      expect(result.performance.p99ResponseTime).toBeLessThan(2000); // 2s for 99th percentile\n    });\n\n    test('should handle structured output processing', async () => {\n      const result = await loadTest('/api/structured/process', {\n        method: 'POST',\n        data: {\n          data: {\n            overallScore: 8.5,\n            dimensions: {\n              accuracy: 0.9,\n              completeness: 0.8\n            }\n          },\n          schema: 'quality_evaluation'\n        },\n        requests: 300,\n        concurrency: 10,\n        warmup: 30\n      });\n\n      console.log('📊 Structured Processing Results:', result);\n\n      expect(result.summary.successRate).toBeGreaterThan(0.98);\n      expect(result.performance.p95ResponseTime).toBeLessThan(800); // 800ms for structured processing\n    });\n  });\n\n  describe('System Resource Utilization', () => {\n    test('should maintain reasonable memory usage under load', async () => {\n      const initialMemory = process.memoryUsage();\n      \n      // Run sustained load\n      const result = await loadTest('/api/enhanced/status', {\n        requests: 500,\n        concurrency: 15,\n        warmup: 50\n      });\n      \n      const finalMemory = process.memoryUsage();\n      const memoryIncrease = finalMemory.heapUsed - initialMemory.heapUsed;\n      \n      console.log('💾 Memory Usage Analysis:', {\n        initial: Math.round(initialMemory.heapUsed / 1024 / 1024) + 'MB',\n        final: Math.round(finalMemory.heapUsed / 1024 / 1024) + 'MB',\n        increase: Math.round(memoryIncrease / 1024 / 1024) + 'MB',\n        maxDuringTest: Math.round(result.system.maxMemoryUsage / 1024 / 1024) + 'MB'\n      });\n      \n      // Memory shouldn't increase more than 100MB during test\n      expect(memoryIncrease).toBeLessThan(100 * 1024 * 1024);\n      expect(result.system.maxMemoryUsage).toBeLessThan(BENCHMARK_CONFIG.MEMORY_LIMIT);\n    });\n\n    test('should handle mixed workload efficiently', async () => {\n      const endpoints = [\n        { path: '/api/health', weight: 0.4 },\n        { path: '/api/enhanced/status', weight: 0.3 },\n        { path: '/api/workers/metrics', weight: 0.2 },\n        { path: '/api/quality/evaluate', method: 'POST', data: { result: 'test', task: { content: 'test' } }, weight: 0.1 }\n      ];\n      \n      const promises = [];\n      const totalRequests = 400;\n      \n      console.log('🔀 Running mixed workload test...');\n      \n      for (let i = 0; i < totalRequests; i++) {\n        const endpoint = selectWeightedEndpoint(endpoints);\n        \n        const promise = loadTest(endpoint.path, {\n          method: endpoint.method || 'GET',\n          data: endpoint.data,\n          requests: 1,\n          concurrency: 1,\n          warmup: 0\n        });\n        \n        promises.push(promise);\n      }\n      \n      const results = await Promise.all(promises);\n      \n      // Aggregate results\n      const aggregated = aggregateResults(results);\n      \n      console.log('📊 Mixed Workload Results:', aggregated);\n      \n      expect(aggregated.summary.successRate).toBeGreaterThan(0.92);\n      expect(aggregated.performance.p95ResponseTime).toBeLessThan(2500);\n    });\n  });\n\n  describe('Stress Testing', () => {\n    test('should survive stress test', async () => {\n      console.log('💪 Starting stress test...');\n      \n      const stressResult = await loadTest('/api/enhanced/status', {\n        requests: 1000,\n        concurrency: 50,\n        warmup: 100\n      });\n      \n      console.log('📊 Stress Test Results:', stressResult);\n      \n      // More lenient requirements for stress test\n      expect(stressResult.summary.successRate).toBeGreaterThan(0.85);\n      expect(stressResult.performance.p99ResponseTime).toBeLessThan(10000); // 10s max\n      \n      // Check system stability\n      const memoryUsageVariation = calculateVariation(stressResult.system.memoryUsage || []);\n      expect(memoryUsageVariation).toBeLessThan(0.5); // Less than 50% variation\n    });\n  });\n\n  describe('Performance Regression Detection', () => {\n    test('should detect performance regressions', async () => {\n      // Baseline measurement\n      const baseline = await loadTest('/api/health', {\n        requests: 100,\n        concurrency: 5,\n        warmup: 10\n      });\n      \n      // Simulated degraded performance\n      const degraded = await loadTest('/api/enhanced/execute', {\n        method: 'POST',\n        data: { task: { content: 'Complex task', type: 'complex_analysis' } },\n        requests: 100,\n        concurrency: 5,\n        warmup: 10\n      });\n      \n      const regressionAnalysis = detectRegression(baseline, degraded);\n      \n      console.log('🔍 Regression Analysis:', regressionAnalysis);\n      \n      // Complex tasks should be slower but not drastically\n      expect(regressionAnalysis.responseTimeRatio).toBeLessThan(5); // No more than 5x slower\n      expect(regressionAnalysis.throughputRatio).toBeGreaterThan(0.2); // At least 20% of baseline throughput\n    });\n  });\n});\n\n// Helper functions\nfunction analyzeScalability(results) {\n  if (results.length < 2) return { degradationRate: 0 };\n  \n  const baseline = results[0];\n  const peak = results[results.length - 1];\n  \n  const responseTimeDegradation = (peak.performance.avgResponseTime - baseline.performance.avgResponseTime) / baseline.performance.avgResponseTime;\n  const throughputDegradation = (baseline.summary.throughput - peak.summary.throughput) / baseline.summary.throughput;\n  \n  return {\n    degradationRate: Math.max(responseTimeDegradation, throughputDegradation),\n    responseTimeDegradation,\n    throughputDegradation,\n    recommendations: generateScalabilityRecommendations(results)\n  };\n}\n\nfunction generateScalabilityRecommendations(results) {\n  const recommendations = [];\n  \n  const highConcurrencyResult = results[results.length - 1];\n  \n  if (highConcurrencyResult.performance.p95ResponseTime > 2000) {\n    recommendations.push('Consider implementing response caching');\n  }\n  \n  if (highConcurrencyResult.summary.successRate < 0.95) {\n    recommendations.push('Implement circuit breaker pattern');\n  }\n  \n  if (highConcurrencyResult.system.avgMemoryUsage > 400 * 1024 * 1024) {\n    recommendations.push('Optimize memory usage');\n  }\n  \n  return recommendations;\n}\n\nfunction selectWeightedEndpoint(endpoints) {\n  const random = Math.random();\n  let cumulativeWeight = 0;\n  \n  for (const endpoint of endpoints) {\n    cumulativeWeight += endpoint.weight;\n    if (random <= cumulativeWeight) {\n      return endpoint;\n    }\n  }\n  \n  return endpoints[0];\n}\n\nfunction aggregateResults(results) {\n  const totalRequests = results.reduce((sum, r) => sum + r.summary.totalRequests, 0);\n  const totalResponses = results.reduce((sum, r) => sum + r.summary.totalResponses, 0);\n  const totalErrors = results.reduce((sum, r) => sum + r.summary.totalErrors, 0);\n  \n  const allResponseTimes = results.flatMap(r => {\n    // Extract response times if available\n    return [r.performance.avgResponseTime];\n  }).filter(t => t > 0);\n  \n  return {\n    summary: {\n      totalRequests,\n      totalResponses,\n      totalErrors,\n      successRate: totalResponses / totalRequests,\n      throughput: results.reduce((sum, r) => sum + r.summary.throughput, 0) / results.length\n    },\n    performance: {\n      avgResponseTime: allResponseTimes.reduce((a, b) => a + b, 0) / allResponseTimes.length,\n      p95ResponseTime: allResponseTimes.sort((a, b) => a - b)[Math.floor(allResponseTimes.length * 0.95)]\n    }\n  };\n}\n\nfunction calculateVariation(values) {\n  if (values.length === 0) return 0;\n  \n  const mean = values.reduce((a, b) => a + b, 0) / values.length;\n  const variance = values.reduce((sum, value) => sum + Math.pow(value - mean, 2), 0) / values.length;\n  const stdDev = Math.sqrt(variance);\n  \n  return stdDev / mean;\n}\n\nfunction detectRegression(baseline, current) {\n  return {\n    responseTimeRatio: current.performance.avgResponseTime / baseline.performance.avgResponseTime,\n    throughputRatio: current.summary.throughput / baseline.summary.throughput,\n    successRateChange: current.summary.successRate - baseline.summary.successRate,\n    isRegression: (\n      current.performance.avgResponseTime > baseline.performance.avgResponseTime * 1.5 ||\n      current.summary.throughput < baseline.summary.throughput * 0.8 ||\n      current.summary.successRate < baseline.summary.successRate - 0.05\n    )\n  };\n}"